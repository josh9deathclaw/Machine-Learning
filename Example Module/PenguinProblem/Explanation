https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough
Tutorial : Train a Machine Learning Model with a custom training loop 
Problem : Categorise Penguins by Species
    - Import a Dataset, Linear Model, Train Model, Evaluate effectiveness, Make Predicitions

Classify Penguins using their body weight, flipper length and beaks, and the length and width of their culmen.
  - Chinstrap, Gentoo and Adelie Penguins

Setup : 
    - Install tfds-nightly for dataset
    - download dataset using tfds.load method
    - 1st 6 rows are features and last column is the label, value want to predict
            - for this dataset, either 0,1 or 2 (corresponds to the penguins names)
    - Create list of species names
    - reduce the dataset to only 4 features for efficiency
Build Linear Model
    - Define the relationship between the body mass, flipper and culmen measurements with the predicted penguin species
    - Good Machine Learning Approach Determines the Model for you
    - Feed enough examples into the right model type and it will learn the relationships for you
Select the Model
    - Nearal Network is Used
        - Find Complex Relationships between features and the label
        - Highly-structured graph, organised into one or more hidden layers
        - Each hidden layer consists of one or more neaurons
            - Fully Connected Neural Network (there are other types)
                - The neurons in one layer recieve input connections from every neuron in the previous layer
        - Training the Model
                - Yields 3 Predictions
                    1. Likelihood (inference)
                    2. ??
Create Model Using Keras
    - tf.keras.Sequential = linear stack of layers
        - constructor : takes a list of layer instances, 2 here, with 10 nodes each 
            - and an output layer, with 3 nodes for the label predictions
                            - 1st layers input_shape parameter corresponds to the number of features from the dataset
    - use ReLU for activation function (non-linearities)
    - Ideal Layers and Neurons depends on the problem and dataset
Using the Model
    - Test on a small batch of feeatures (5)
    - Each returns a logit for each class, convert logits into a probability using the 'softmax' function
    - Use tf.math.argmax : will give the predicted class index
        - Currently the predictions are very poor due to the model being untrained
Train the Model
    - Optimise the model over time, it will learn the dataset
    - Train the model until it can look at unseen data and make predictions
            - Learning to much will lead to it only working for that dataset and not generally
                    - Called overfitting
    - Example of Supervised Machine Learning (trained from examples that contain labels)
    - In unsupervised machine learning, they dont include abels, but find patterns among the features instead
Define the Loss and Gradient Function
    - How off a Models Prediction is from the desired label
    - Calculate using tf.keras.losses.SparseCategoricalCrossentropy
            - Takes models class probability and desired label and returns the average loss
    - Use tf.GradientTape to calculate the gradients for optimisation
Create an Optimiser
    - Applies computed gradient to the models parameters to minimise the loss function
            - think of loss function as a curved surface
                    - find the lowest point by walkig aroundd
                            - gradient point in the direction of the steepest ascent
                                    - therefore you will travel the opposite way and move down the hill
        - Calc loss and gradient iteratively for each batch
                - Model will find the best combination of weight and bias to minimise loss
    - TensorFlow has access to many optimisation algorithms (this eg. uses SGD)
            - tf.keras.optimizers.SGD : Stochastic Gradient Descent Algorithm
                    - Learning Rate Parameter : sets the srtep size to take for each iteration down the hill
                            - Ajust to achieve better results
                                    - in eg. set to 0.01 and is a scalar multiplied by the gradient at each iteration of the training
Training Loop
    - Feeds the dataset examples into the model
        1. Iterate each epoch. An epoch is one pass through the dataset.
        2. Within an epoch, iterate over each example in the training Dataset grabbing its features (x) and label (y).
        3. Using the example's features, make a prediction and compare it with the label. Measure the inaccuracy of the prediction and use that to calculate the model's loss and gradients.
        4. Use an optimizer to update the model's parameters.
        5. Keep track os some stats for visualisation
        6. Repear for each epoch
                - num_epochs : number of times to loop over the dataset collection
                    - higher does not equal better, need to adjust till least amount of loss is found
    - Can use Keras in built method to train the model : Model.fit(ds_train_batch)
Visualise the Loss Function Over Time
    - Use TensorBoard
            - Use matplotlib module
                    - Want loss to decrease and accuracy to increase
Evaluation
    - Pass some measurements to the modela dn ask it to predict what species they represent
    - Compare the prediction to the actual label
    - Evaluate the Model on the Test Dataset
            - Only evaluates a single epoch of the test data    
    - Can use model.evluate(ds_test, return_dict=True) keras function to get accuracy on test dataset
Use Trained Model to make Predictions
    - Make Predictions on Unlabeled Examples
    - IRL get it from Apps, CSV files, data feeds


