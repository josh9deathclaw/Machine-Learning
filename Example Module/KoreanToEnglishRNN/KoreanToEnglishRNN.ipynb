{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b266e9d-e505-4447-a20b-701fbc21f7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Bidirectional, Concatenate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06be5964-0e82-40ab-b05b-0cdc30a2551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 20\n",
    "latent_dim = 256\n",
    "num_samples = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69904c05-fb74-4e09-8dca-4f388d8eba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'kor.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57b3628-9646-475c-9d06-291798ddecdf",
   "metadata": {},
   "source": [
    "Read and Prepare the Data :\n",
    "    - read data from file\n",
    "    - tokenize characters\n",
    "    - prepare input and output sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8491431b-9ac7-41bb-a0ec-1d6ea448db05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines read: 5891\n"
     ]
    }
   ],
   "source": [
    "input_texts = []\n",
    "output_texts = []\n",
    "input_characters = set()\n",
    "output_characters = set()\n",
    "with open(data_path, 'r', encoding = 'utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    print(\"Number of lines read:\", len(lines))\n",
    "for line in lines[:min(num_samples,len(lines)-1)]:\n",
    "    input_text, output_text, _ = line.split('\\t')\n",
    "    \n",
    "    # We use 'tab' as the 'start sequence' character\n",
    "    # for the targets, and '\\n' as the 'end sequence' character.\n",
    "    \n",
    "    output_text = '\\t' + output_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    output_texts.append(output_text)\n",
    "    \n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in output_text:\n",
    "        if char not in output_characters:\n",
    "            output_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "output_characters = sorted(list(output_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(output_characters)\n",
    "max_encoder_seq_length = max([len(text) for text in input_texts])\n",
    "max_decoder_seq_length = max([len(text) for text in output_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bcaa0538-90ae-4f84-b21d-4b045a6c3d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input texts: 5000\n",
      "Number of output texts: 5000\n",
      "Number of encoder tokens: 72\n",
      "Number of decoder tokens: 961\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of input texts:\", len(input_texts))\n",
    "print(\"Number of output texts:\", len(output_texts))\n",
    "#print(output_characters)\n",
    "print(\"Number of encoder tokens:\", num_encoder_tokens)\n",
    "print(\"Number of decoder tokens:\", num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33b2196-06b8-4bf7-a358-a452355c7217",
   "metadata": {},
   "source": [
    "Create Token Dictionary for Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26fba363-636c-4869-913e-b21200327e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_token_index = dict(\n",
    "    [(char,i) for i,char in enumerate(input_characters)])\n",
    "output_token_index = dict(\n",
    "    [(char,i) for i,char in enumerate(output_characters)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467cd6b6-2722-4718-86db-b2746d69ced7",
   "metadata": {},
   "source": [
    "Data Preparation : \n",
    "    - Initisalise Numpy Arrays for :\n",
    "            - Encoder Input, Decoder Input and Decoder Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7bf49c1b-6605-4ec0-baf5-18c77d6ec02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pairs = len(input_texts)\n",
    "max_english_sentence_length = max_encoder_seq_length\n",
    "max_french_sentence_length = max_decoder_seq_length\n",
    "num_english_characters = num_encoder_tokens\n",
    "Num_french_characters = num_decoder_tokens\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts),max_encoder_seq_length,num_encoder_tokens),dtype = 'float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length , num_decoder_tokens), dtype = 'float32')\n",
    "decoder_output_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length,num_decoder_tokens) , dtype = 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4bf005-b95c-4b76-bda9-305eac375ae0",
   "metadata": {},
   "source": [
    "Data Encoding : one-hot encoded vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "525d8a83-1473-4cb1-b742-80c4b07414f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(input_text,output_text) in enumerate(zip(input_texts,output_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i,t,input_token_index[char]] = 1.\n",
    "    encoder_input_data[i,t+1:,input_token_index[' ']] = 1.\n",
    "    \n",
    "    for t, char in enumerate(output_text):\n",
    "        # decoder_output_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i,t,output_token_index[char]] = 1.\n",
    "        if t>0:\n",
    "            # decoder_output_data will be ahead by one timestep\n",
    "            # and will not include the start character\n",
    "            decoder_output_data[i,t-1,output_token_index[char]] = 1.\n",
    "    decoder_input_data[i,t+1:, output_token_index[' ']] = 1.\n",
    "    decoder_output_data[i , t: , output_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03718002-bb45-4044-93e9-717784ee08f7",
   "metadata": {},
   "source": [
    "Define Encoder : \n",
    "    - unidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4dc0aa45-5077-47f7-a209-aa9840c9bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an input sequence and process it:\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state= True)\n",
    "encoder_outputs,state_h,state_c = encoder(encoder_inputs)\n",
    "# we discard 'encoder_outputs' and only keep the states.\n",
    "encoder_states = [state_h,state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbfec9-6ee0-4770-bb2b-77fb4022aa92",
   "metadata": {},
   "source": [
    "Deifne Decoder : - unidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f10077aa-0e58-42c0-a98b-90ce1190e8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the decoder, using encoder_states as initial states:\n",
    "decoder_inputs= Input(shape=(None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(latent_dim,return_sequences = True, return_state = True)\n",
    "# We set our decoder to return full output sequences, and to return internal states as well but we don’t use this internal states in the training model,  \n",
    "#  but we will use them in inference.\n",
    "decoder_outputs, _ ,_ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens,activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a20e31-a7f9-4823-acf0-93df7f2a422d",
   "metadata": {},
   "source": [
    "Define, Compile and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e3d7a83-efc9-4826-b179-ddde05a79a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "63/63 [==============================] - 21s 257ms/step - loss: 1.9048 - accuracy: 0.7073 - val_loss: 2.5213 - val_accuracy: 0.5960\n",
      "Epoch 2/20\n",
      "63/63 [==============================] - 16s 261ms/step - loss: 1.6124 - accuracy: 0.7199 - val_loss: 2.4623 - val_accuracy: 0.6004\n",
      "Epoch 3/20\n",
      "63/63 [==============================] - 16s 247ms/step - loss: 1.5105 - accuracy: 0.7320 - val_loss: 2.3807 - val_accuracy: 0.6127\n",
      "Epoch 4/20\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 1.4132 - accuracy: 0.7576 - val_loss: 2.2179 - val_accuracy: 0.6371\n",
      "Epoch 5/20\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 1.3195 - accuracy: 0.7674 - val_loss: 2.0855 - val_accuracy: 0.6490\n",
      "Epoch 6/20\n",
      "63/63 [==============================] - 16s 250ms/step - loss: 1.2482 - accuracy: 0.7733 - val_loss: 1.9479 - val_accuracy: 0.6591\n",
      "Epoch 7/20\n",
      "63/63 [==============================] - 16s 260ms/step - loss: 1.2419 - accuracy: 0.7703 - val_loss: 1.8498 - val_accuracy: 0.6693\n",
      "Epoch 8/20\n",
      "63/63 [==============================] - 17s 263ms/step - loss: 0.9545 - accuracy: 0.8129 - val_loss: 1.5837 - val_accuracy: 0.7017\n",
      "Epoch 15/20\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 0.9296 - accuracy: 0.8171 - val_loss: 1.5663 - val_accuracy: 0.7031\n",
      "Epoch 16/20\n",
      "63/63 [==============================] - 17s 268ms/step - loss: 0.9066 - accuracy: 0.8204 - val_loss: 1.5412 - val_accuracy: 0.7109\n",
      "Epoch 17/20\n",
      "63/63 [==============================] - 16s 263ms/step - loss: 0.8837 - accuracy: 0.8239 - val_loss: 1.5388 - val_accuracy: 0.7077\n",
      "Epoch 18/20\n",
      "63/63 [==============================] - 16s 250ms/step - loss: 0.8662 - accuracy: 0.8263 - val_loss: 1.5157 - val_accuracy: 0.7145\n",
      "Epoch 19/20\n",
      "63/63 [==============================] - 16s 251ms/step - loss: 0.8466 - accuracy: 0.8295 - val_loss: 1.5132 - val_accuracy: 0.7121\n",
      "Epoch 20/20\n",
      "63/63 [==============================] - 17s 278ms/step - loss: 0.8295 - accuracy: 0.8317 - val_loss: 1.4904 - val_accuracy: 0.7170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21f90d2ce80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# 'encoder_input_data' & 'decoder_input_data' into 'decoder_output_data'\n",
    "model = Model([encoder_inputs,decoder_inputs], decoder_outputs)\n",
    "#Run training:\n",
    "model.compile(optimizer='rmsprop', loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.fit([encoder_input_data,decoder_input_data], decoder_output_data,\n",
    "         batch_size=batch_size,\n",
    "         epochs = epochs,\n",
    "         validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62d54077-1536-49f0-9acd-ddf697abf425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 468ms/step\n",
      "1/1 [==============================] - 1s 519ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Go.\n",
      "Decoded sentence: 누군가 있어.\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Hi.\n",
      "Decoded sentence: 그녀는 그 사람은 아직 것을 보다.\n",
      "\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Run!\n",
      "Decoded sentence: 이 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Run.\n",
      "Decoded sentence: 이 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Who?\n",
      "Decoded sentence: 우리는 아직도 수 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Wow!\n",
      "Decoded sentence: 우리는 그 사람이 아니다.\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Duck!\n",
      "Decoded sentence: 이 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Fire!\n",
      "Decoded sentence: 누군가 있어.\n",
      "\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Help!\n",
      "Decoded sentence: 그녀는 그 사람은 아직 것을 보다.\n",
      "\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Hide.\n",
      "Decoded sentence: 그 사람들은 아니야.\n",
      "\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Jump!\n",
      "Decoded sentence: 모두 가 있어.\n",
      "\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Jump.\n",
      "Decoded sentence: 모두 가 있어.\n",
      "\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Stay.\n",
      "Decoded sentence: 너 게 해.\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Wait!\n",
      "Decoded sentence: 이 사람들은 무슨 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "ProjectGurukul Project: English to Korean Translation \n",
      "Input sentence: Wait!\n",
      "Decoded sentence: 이 사람들은 무슨 있어?\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# take one sequence for trying out decoding:\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     input_seq \u001b[38;5;241m=\u001b[39m encoder_input_data[seq_index:seq_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m---> 43\u001b[0m     decoded_sentences \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProjectGurukul Project: English to Korean Translation \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput sentence:\u001b[39m\u001b[38;5;124m'\u001b[39m, input_texts[seq_index])\n",
      "Cell \u001b[1;32mIn[21], line 25\u001b[0m, in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq)\u001b[0m\n\u001b[0;32m     23\u001b[0m decoded_sentences \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stop_condition:\n\u001b[1;32m---> 25\u001b[0m     output_tokens,h,c \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_seq\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstates_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     sampled_token_index \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(output_tokens[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n\u001b[0;32m     29\u001b[0m     sampled_char \u001b[38;5;241m=\u001b[39m reverse_output_char_index[sampled_token_index]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\engine\\training.py:2220\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2211\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2212\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2213\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2214\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2217\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2218\u001b[0m         )\n\u001b[1;32m-> 2220\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2224\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2227\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2228\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\engine\\data_adapter.py:1582\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\engine\\data_adapter.py:1262\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1261\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1277\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\engine\\data_adapter.py:349\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m    347\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[1;32m--> 349\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\keras\\engine\\data_adapter.py:401\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[1;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuffle:\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;66;03m# See b/141490660 for more details.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m     options\u001b[38;5;241m.\u001b[39mexperimental_external_state_policy \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    399\u001b[0m         tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mExternalStatePolicy\u001b[38;5;241m.\u001b[39mIGNORE\n\u001b[0;32m    400\u001b[0m     )\n\u001b[1;32m--> 401\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2879\u001b[0m, in \u001b[0;36mDatasetV2.with_options\u001b[1;34m(self, options, name)\u001b[0m\n\u001b[0;32m   2853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_options\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2854\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a new `tf.data.Dataset` with the given options set.\u001b[39;00m\n\u001b[0;32m   2855\u001b[0m \n\u001b[0;32m   2856\u001b[0m \u001b[38;5;124;03m  The options are \"global\" in the sense they apply to the entire dataset.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2877\u001b[0m \u001b[38;5;124;03m    ValueError: when an option is set more than once to a non-default value\u001b[39;00m\n\u001b[0;32m   2878\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2879\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_OptionsDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5736\u001b[0m, in \u001b[0;36m_OptionsDataset.__init__\u001b[1;34m(self, input_dataset, options, name)\u001b[0m\n\u001b[0;32m   5734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m   5735\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[1;32m-> 5736\u001b[0m   variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39moptions_dataset(\n\u001b[0;32m   5737\u001b[0m       input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor, options_pb\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[0;32m   5738\u001b[0m       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m   5739\u001b[0m \u001b[38;5;28msuper\u001b[39m(_OptionsDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n\u001b[0;32m   5741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_attr:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Practice\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:4821\u001b[0m, in \u001b[0;36moptions_dataset\u001b[1;34m(input_dataset, serialized_options, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   4819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   4820\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4821\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4822\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOptionsDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mserialized_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4823\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4824\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   4826\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define sampling models:\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape = (latent_dim,))\n",
    "decoder_state_input_c = Input(shape = (latent_dim,))\n",
    "decoder_input_states = [decoder_state_input_h,decoder_state_input_c]\n",
    "decoder_outputs,state_h,state_c = decoder_lstm(decoder_inputs, initial_state=decoder_input_states)\n",
    "decoder_states = [state_h,state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs]+decoder_input_states,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i,char) for char,i in input_token_index.items())\n",
    "reverse_output_char_index = dict(\n",
    "    (i,char) for char,i in output_token_index.items())\n",
    "def decode_sequence(input_seq):\n",
    "    states_value= encoder_model.predict(input_seq)\n",
    "    output_seq = np.zeros((1,1,num_decoder_tokens))\n",
    "    output_seq[0,0,output_token_index['\\t']] = 1\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentences = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens,h,c = decoder_model.predict(\n",
    "            [output_seq]+ states_value)\n",
    "        \n",
    "        sampled_token_index = np.argmax(output_tokens[0,-1, :])\n",
    "        sampled_char = reverse_output_char_index[sampled_token_index]\n",
    "        decoded_sentences += sampled_char\n",
    "        if(sampled_char == '\\n' or len(decoded_sentences) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "        \n",
    "        #update the target sequence (of length 1):\n",
    "        output_seq = np.zeros((1,1,num_decoder_tokens))\n",
    "        output_seq[0,0,sampled_token_index] = 1\n",
    "        \n",
    "        states_value = [h,c]\n",
    "    return decoded_sentences\n",
    "for seq_index in range(20):\n",
    "    # take one sequence for trying out decoding:\n",
    "    input_seq = encoder_input_data[seq_index:seq_index+1]\n",
    "    decoded_sentences = decode_sequence(input_seq)\n",
    "    print('ProjectGurukul Project: English to Korean Translation ')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:' , decoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679424b0-64a1-468b-97a9-aea87e7c5a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Josh",
   "language": "python",
   "name": "practice"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
